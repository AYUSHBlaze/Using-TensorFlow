{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "pd.options.display.max_rows=10\n",
    "pd.options.display.float_format=\"{:.1f}\".format\n",
    "\n",
    "np.set_printoptions(linewidth = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 127, 100, 156, 239, 224, 177, 213, 159,  70,  13,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 110, 250, 254, 254, 254, 254, 254, 254, 254, 254, 184,  10,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 216, 254, 254, 254, 254, 254, 254, 254, 254, 254, 251,  54,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   3, 131, 197,  68, 137, 101,  83,  41,  70, 221, 254, 108,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  58, 254, 216,  11,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 110, 254, 254,  24,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   4,  83, 247, 254, 192,  10,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  37, 124, 254, 254, 250,  47,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 113, 178, 250, 254, 254, 254, 252, 178, 128,  50,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  69, 252, 254, 254, 254, 254, 254, 254, 254, 254, 153,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 141, 252, 254, 241, 241, 254, 247, 252, 254, 254, 153,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  68,  82,   5,   5,  82,  37,  65, 167, 254, 190,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 162, 254, 153,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1, 172, 253,  75,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 102, 254, 152,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  38, 230, 216,  20,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,  71, 222, 254, 142,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  66, 254, 254, 157,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   4,  34,  34,  78, 161, 226, 249, 254, 154,   6,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  96, 184, 254, 254, 254, 254, 254, 249,  93,   5,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[2917]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x22054ea1a88>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[2917])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  58, 254, 216,  11,   0,   0,   0,   0,   0,   0,   0,   0], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[2917][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[2917][10][16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         0.         0.         0.         0.         0.55294118 0.88627451 0.22352941 0.         0.         0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "x_train_normalized=x_train/255.0\n",
    "x_test_normalized=x_test/255.0\n",
    "print(x_train_normalized[2900][12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_curve(epochs, hist, list_of_metrics):\n",
    "    plt.figure()\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    \n",
    "    for m in list_of_metrics:\n",
    "        x=hist[m]\n",
    "        plt.plot(epochs[1:], x[1:], label=m)\n",
    "        \n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(my_learning_rate):\n",
    "    model=tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
    "    model.add(tf.keras.layers.Dense(units=256, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dropout(rate=0.3))\n",
    "    model.add(tf.keras.layers.Dense(units=10, activation=\"softmax\"))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=my_learning_rate),\n",
    "                 loss=\"sparse_categorical_crossentropy\",\n",
    "                 metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def train_model(model, train_features, train_label, epochs, batch_size=None, validation_split=0.1):\n",
    "    history=model.fit(x=train_features, y=train_label, batch_size=batch_size, epochs=epochs, shuffle=True, validation_split=validation_split)\n",
    "    epochs=history.epoch\n",
    "    hist=pd.DataFrame(history.history)\n",
    "    \n",
    "    return epochs, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/50\n",
      "48000/48000 [==============================] - 2s 41us/sample - loss: 0.9977 - accuracy: 0.7070 - val_loss: 0.3659 - val_accuracy: 0.8916\n",
      "Epoch 2/50\n",
      "48000/48000 [==============================] - 1s 28us/sample - loss: 0.4008 - accuracy: 0.8804 - val_loss: 0.2780 - val_accuracy: 0.9202\n",
      "Epoch 3/50\n",
      "48000/48000 [==============================] - 1s 28us/sample - loss: 0.3023 - accuracy: 0.9104 - val_loss: 0.2331 - val_accuracy: 0.9333\n",
      "Epoch 4/50\n",
      "48000/48000 [==============================] - 1s 28us/sample - loss: 0.2516 - accuracy: 0.9274 - val_loss: 0.1996 - val_accuracy: 0.9429\n",
      "Epoch 5/50\n",
      "48000/48000 [==============================] - 2s 34us/sample - loss: 0.2158 - accuracy: 0.9381 - val_loss: 0.1773 - val_accuracy: 0.9496\n",
      "Epoch 6/50\n",
      "48000/48000 [==============================] - 2s 32us/sample - loss: 0.1901 - accuracy: 0.9449 - val_loss: 0.1597 - val_accuracy: 0.9560\n",
      "Epoch 7/50\n",
      "48000/48000 [==============================] - 2s 33us/sample - loss: 0.1700 - accuracy: 0.9507 - val_loss: 0.1470 - val_accuracy: 0.9583\n",
      "Epoch 8/50\n",
      "48000/48000 [==============================] - 1s 29us/sample - loss: 0.1532 - accuracy: 0.9563 - val_loss: 0.1381 - val_accuracy: 0.9605\n",
      "Epoch 9/50\n",
      "48000/48000 [==============================] - 1s 28us/sample - loss: 0.1415 - accuracy: 0.9595 - val_loss: 0.1288 - val_accuracy: 0.9619\n",
      "Epoch 10/50\n",
      "48000/48000 [==============================] - 1s 28us/sample - loss: 0.1290 - accuracy: 0.9632 - val_loss: 0.1216 - val_accuracy: 0.9642\n",
      "Epoch 11/50\n",
      "48000/48000 [==============================] - 1s 31us/sample - loss: 0.1188 - accuracy: 0.9653 - val_loss: 0.1157 - val_accuracy: 0.9657\n",
      "Epoch 12/50\n",
      "48000/48000 [==============================] - 2s 32us/sample - loss: 0.1142 - accuracy: 0.9666 - val_loss: 0.1126 - val_accuracy: 0.9665\n",
      "Epoch 13/50\n",
      "48000/48000 [==============================] - 1s 29us/sample - loss: 0.1059 - accuracy: 0.9697 - val_loss: 0.1065 - val_accuracy: 0.9676\n"
     ]
    }
   ],
   "source": [
    "learning_rate=0.003\n",
    "epochs=50\n",
    "batch_size=4000\n",
    "validation_split=0.2\n",
    "\n",
    "my_model=create_model(learning_rate)\n",
    "\n",
    "epochs, hist=train_model(my_model, x_train_normalized, y_train, epochs, batch_size, validation_split)\n",
    "list_of_metrics_to_plot=['accuracy']\n",
    "plot_curve(epochs, hist, list_of_metrics_to_plot)\n",
    "\n",
    "print(\"/n Evaluating against Test set:\")\n",
    "my_model.evaluate(x=x_test_normalized, y=y_test, batch_size=batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
